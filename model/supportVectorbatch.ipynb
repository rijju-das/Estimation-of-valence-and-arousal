{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "\n",
    "# Directories and file paths\n",
    "train_dir = 'train_set\\\\images'\n",
    "val_dir = 'val_set\\\\images'\n",
    "test_dir = 'test_set\\\\images'\n",
    "train_ann_file = 'train_annotation.csv'\n",
    "val_ann_file = 'val_annotation.csv'\n",
    "test_ann_file = 'test_annotation.csv'\n",
    "img_width = 227\n",
    "img_height = 227\n",
    "batch_size = 20\n",
    "num_emotions = 8\n",
    "\n",
    "# One-hot encode emotion labels\n",
    "def one_hot_encode(number, num_classes=num_emotions):\n",
    "    one_hot_vector = np.zeros(num_classes)\n",
    "    one_hot_vector[number] = 1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Function to load and preprocess a batch of data\n",
    "def load_batch(dir_path, ann_file, batch_paths, dims):\n",
    "    images = []\n",
    "    valences = []\n",
    "    arousals = []\n",
    "    emotions = []\n",
    "    \n",
    "    anno = pd.read_csv(ann_file)\n",
    "    \n",
    "    for filename in batch_paths:\n",
    "        img_path = os.path.join(dir_path, filename)\n",
    "        img = imread(img_path)\n",
    "        img_resized = resize(img, (img_height, img_width))\n",
    "        images.append(img_resized.flatten())  # Flatten image to 1D array\n",
    "        \n",
    "        row = anno[anno[\"filename\"] == int(filename.split(\".\")[0])]\n",
    "        if not row.empty:\n",
    "            valences.append(row[\"Valance\"].values[0])\n",
    "            arousals.append(row[\"Arousal\"].values[0])\n",
    "            emotions.append(one_hot_encode(row[\"Expression\"].values[0]))\n",
    "    \n",
    "    images = np.asarray(images)\n",
    "    valences = np.asarray(valences)\n",
    "    arousals = np.asarray(arousals)\n",
    "    # print(emotions)\n",
    "    emotions = np.asarray(emotions)\n",
    "    \n",
    "    return images, valences, arousals, emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concordance_correlation_coefficient\n",
    "def CCC(y_true, y_pred):\n",
    "    \"\"\"Calculate the Concordance Correlation Coefficient (CCC) between true and predicted values.\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    mean_true = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    \n",
    "    var_true = np.var(y_true)\n",
    "    var_pred = np.var(y_pred)\n",
    "    \n",
    "    covar = np.mean((y_true - mean_true) * (y_pred - mean_pred))\n",
    "    \n",
    "    ccc = (2 * covar) / (var_true + var_pred + (mean_true - mean_pred)**2)\n",
    "    \n",
    "    return ccc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate batches of data\n",
    "def data_generator(dir_path, ann_file, images, batch_size):\n",
    "    while True:\n",
    "        batch_paths = np.random.choice(images, size=batch_size)\n",
    "        yield load_batch(dir_path, ann_file, batch_paths, (img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of image filenames\n",
    "train_img = [f for f in os.listdir(train_dir)]\n",
    "val_img = [f for f in os.listdir(val_dir)]\n",
    "test_img = [f for f in os.listdir(test_dir)]\n",
    "\n",
    "# Initialize generators\n",
    "train_gen = data_generator(train_dir, train_ann_file, train_img, batch_size)\n",
    "val_gen = data_generator(val_dir, val_ann_file, val_img, batch_size)\n",
    "test_gen = data_generator(test_dir, val_ann_file, test_img, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create SVM models\n",
    "svr_valence = SVR(kernel='rbf')\n",
    "svr_arousal = SVR(kernel='rbf')\n",
    "svc_emotion = SVC(kernel='rbf', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Batch training\n",
    "num_batches = len(train_img) // batch_size\n",
    "\n",
    "for _ in range(3):\n",
    "    X_train_batch, y_train_valence_batch, y_train_arousal_batch, y_train_emotion_batch = next(train_gen)\n",
    "    \n",
    "    X_train_scaled_batch = scaler.fit_transform(X_train_batch)\n",
    "    \n",
    "    # print(y_train_arousal_batch)\n",
    "    \n",
    "    svr_valence.fit(X_train_scaled_batch, y_train_valence_batch)\n",
    "    svr_arousal.fit(X_train_scaled_batch, y_train_arousal_batch)\n",
    "    svc_emotion.fit(X_train_scaled_batch, np.argmax(y_train_emotion_batch, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "X_val, y_val_valence, y_val_arousal, y_val_emotion = next(val_gen)\n",
    "X_val_scaled = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_predictions = svr_valence.predict(X_val_scaled)\n",
    "arousal_predictions = svr_arousal.predict(X_val_scaled)\n",
    "emotion_predictions = svc_emotion.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence MSE: 0.2718\n",
      "Arousal MSE: 0.2496\n",
      "Emotion Accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "valence_mse = np.mean((valence_predictions - y_val_valence) ** 2)\n",
    "arousal_mse = np.mean((arousal_predictions - y_val_arousal) ** 2)\n",
    "emotion_accuracy = np.mean(emotion_predictions == y_val_emotion.argmax(axis=1))\n",
    "\n",
    "print(f'Valence MSE: {valence_mse:.4f}')\n",
    "print(f'Arousal MSE: {arousal_mse:.4f}')\n",
    "print(f'Emotion Accuracy: {emotion_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "X_test, y_test_valence, y_test_arousal, y_test_emotion = next(test_gen)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_valence_predictions = svr_valence.predict(X_test_scaled)\n",
    "test_arousal_predictions = svr_arousal.predict(X_test_scaled)\n",
    "test_emotion_predictions = svc_emotion.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Valence MSE: 0.2031\n",
      "Test Arousal MSE: 0.2248\n",
      "Test Emotion Accuracy: 0.3000\n",
      "Test Valence CCC: 0.1013\n"
     ]
    }
   ],
   "source": [
    "# Calculate test set evaluation metrics\n",
    "test_valence_mse = np.mean((test_valence_predictions - y_test_valence) ** 2)\n",
    "test_arousal_mse = np.mean((test_arousal_predictions - y_test_arousal) ** 2)\n",
    "test_emotion_accuracy = np.mean(test_emotion_predictions == y_test_emotion.argmax(axis=1))\n",
    "test_valenece_ccc = CCC(y_test_valence, test_valence_predictions)\n",
    "\n",
    "print(f'Test Valence MSE: {test_valence_mse:.4f}')\n",
    "print(f'Test Arousal MSE: {test_arousal_mse:.4f}')\n",
    "print(f'Test Emotion Accuracy: {test_emotion_accuracy:.4f}')\n",
    "print(f'Test Valence CCC: {test_valenece_ccc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
